# ENV: Sets the application environment.
# Used to differentiate between development and production behaviors.
# Can be 'dev' for development, or other values as needed by your application logic.
ENV=dev

# LLM Configuration (for the main response generator)
#
# LLM_PROVIDER: Specifies the large language model (LLM) provider to use for generating responses.
# Supported values: 'ollama', 'openai', 'anthropic', 'cohere', 'gemini'.
LLM_PROVIDER=ollama
# LLM_MODEL_NAME: The specific model name from the chosen LLM provider.
# Example for Ollama: 'mistral'; for OpenAI: 'gpt-4o'; for Gemini: 'gemini-pro'.
LLM_MODEL_NAME=mistral
# LLM_API_KEY: Your API key for the chosen LLM provider.
# If using Ollama locally without an API key, this can be an empty string or '1234' as a placeholder.
LLM_API_KEY=1234
# LLM_TEMPERATURE: Controls the randomness of the LLM's output.
# A value of 0 makes the output more deterministic and factual. Higher values lead to more creative responses.
LLM_TEMPERATURE=0

# TOOL_EVALUATOR_LLM Configuration (for deciding which tool to use, e.g., RAG or direct response)
#
# TOOL_EVALUATOR_LLM_PROVIDER: LLM provider for the tool evaluator. Defaults to LLM_PROVIDER if not set.
TOOL_EVALUATOR_LLM_PROVIDER=ollama
# TOOL_EVALUATOR_LLM_MODEL_NAME: Model name for the tool evaluator. Defaults to LLM_MODEL_NAME if not set.
TOOL_EVALUATOR_LLM_MODEL_NAME=mistral
# TOOL_EVALUATOR_LLM_API_KEY: API key for the tool evaluator LLM. Defaults to LLM_API_KEY if not set.
TOOL_EVALUATOR_LLM_API_KEY=1234
# TOOL_EVALUATOR_LLM_TEMPERATURE: Temperature for the tool evaluator LLM. Defaults to LLM_TEMPERATURE if not set.
TOOL_EVALUATOR_LLM_TEMPERATURE=0

# TEXT_EMBEDDING Configuration (for vector database embeddings)
#
# TEXT_EMBEDDING_PROVIDER: LLM provider for generating text embeddings. Defaults to LLM_PROVIDER.
# Supported values: 'ollama', 'openai', 'cohere', 'gemini'.
TEXT_EMBEDDING_PROVIDER=ollama
# TEXT_EMBEDDING_MODEL_NAME: Model name for text embeddings.
# Example for Gemini: 'models/text-embedding-004'.
TEXT_EMBEDDING_MODEL_NAME=mistral
# TEXT_EMBEDDING_API_KEY: API key for the embedding provider. Defaults to LLM_API_KEY.
TEXT_EMBEDDING_API_KEY=1234

# General File Paths
#
# DATA_DIR: Directory for persistent data (e.g., uploaded documents for RAG).
# Use 'data' for local runs, or '/app/data' when running inside Docker containers.
DATA_DIR=data
# PROMPTS_DIR: Directory where prompt templates are stored.
# Use 'prompts' for local runs, or '/app/prompts' when running inside Docker containers.
PROMPTS_DIR=prompts

# Frontend API URL
#
# API_URL: The base URL of the FastAPI backend. The frontend will use this to communicate.
API_URL=http://localhost:8000

# Database Configuration (for chat history and checkpointing)
#
# POSTGRES_URI: Connection string for your PostgreSQL database.
# If running with Docker Compose, this will typically point to the 'postgres' service within the Docker network.
POSTGRES_URI=postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable

# Vector Database Configuration (Milvus)
#
# MILVUS_URI: The URI for your Milvus vector database instance.
# If running with Docker Compose, this will typically point to the 'milvus' service.
MILVUS_URI=http://localhost:19530
# MILVUS_USERNAME: (Optional) Username for Milvus authentication.
MILVUS_USERNAME=admin
# MILVUS_PASSWORD: (Optional) Password for Milvus authentication.
MILVUS_PASSWORD=your_password
# MILVUS_COLLECTION: The name of the collection in Milvus where documents will be stored.
MILVUS_COLLECTION=your_collection_name
